{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72647dea-f694-4e34-9404-40718840f68f",
   "metadata": {},
   "source": [
    "Q1. Expalin the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results.\n",
    "\n",
    "Assumptions in Anova\n",
    "\n",
    "1) Normality of sampling Distribution of Means\n",
    " The distribution of sample means is normaly distributed\n",
    " \n",
    "2) Absence of outliers\n",
    " Outlying score need to be removed from data set\n",
    " \n",
    "3) Homogenity of Variance \n",
    "\n",
    "Each one of the population it should have same variance\n",
    "population variance is different levels of each independent variable are equal\n",
    " \n",
    "4) Sample are independent and random  \n",
    "\n",
    "The assumption that samples are independent and random is an important requirement for many statistical analyses, including ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a474e93-9ce8-4a8b-8745-cdd4da30e8f6",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ae205-ead2-4363-b792-7b835d013cb1",
   "metadata": {},
   "source": [
    "The three types of ANOVA are:\n",
    "\n",
    "1) One-Way ANOVA: One-Way ANOVA is used when comparing the means of three or more independent groups or levels of a single categorical variable. It determines whether there are any statistically significant differences among the means of the groups. For example, if you want to compare the average test scores of students from three different schools, you would use a One-Way ANOVA.\n",
    "\n",
    "2) Two-Way ANOVA: Two-Way ANOVA is used when examining the influence of two independent categorical variables (factors) on a continuous dependent variable. It allows you to investigate main effects (the effects of each individual factor) and interaction effects (the combined effects of the factors). For example, if you want to study the effects of both gender and age group on the average income of individuals, you would use a Two-Way ANOVA.\n",
    "\n",
    "3) Repeated Measures ANOVA: Repeated Measures ANOVA is used when comparing the means of a single group or subject across multiple time points or conditions. It is suitable for analyzing within-subject designs where the same participants are measured under different conditions or at different time intervals. For example, if you want to assess the effectiveness of a drug treatment by measuring patients' blood pressure before treatment, during treatment, and after treatment, you would use a Repeated Measures ANOVA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d719d59-ee90-466b-878c-fd51b0e3bb56",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bc721c-641a-41a3-b8ce-daac39cd2fc1",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the division of the total variance observed in a dataset into different components associated with various sources of variation. It involves decomposing the overall variability in the data into meaningful parts, allowing for the examination of the contributions of different factors and error.\n",
    "\n",
    "In ANOVA, the total variance is divided into two main components:\n",
    "\n",
    "Between-group variance: This component of variance represents the differences or variations among the group means. It reflects the variability that can be attributed to the effect of the independent variable or factor being studied. It is also known as the \"explained\" variance because it accounts for the variation explained by the factors in the model.\n",
    "\n",
    "Within-group variance (or error variance): This component of variance represents the variability within each group or condition that is not explained by the independent variable. It captures the random variation or error in the data that cannot be attributed to the factors under investigation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e96c3e-97f8-4532-a2b9-f32d19f86a00",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "477dc08a-33d5-4531-8b51-990638510879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of squares (SST): 53.33333333333333\n",
      "Explained sum of squares (SSE): 23.33333333333333\n",
      "Residual sum of squares (SSR): 30.0\n",
      "F-value: 4.666666666666668\n",
      "p-value: 0.031676352024078334\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Define the data for each group\n",
    "group1 = [3, 4, 5, 6, 7]\n",
    "group2 = [1, 2, 3, 4, 5]\n",
    "group3 = [4, 5, 6, 7, 8]\n",
    "\n",
    "# Combine the data into a single array\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Define the group labels\n",
    "labels = ['Group 1'] * len(group1) + ['Group 2'] * len(group2) + ['Group 3'] * len(group3)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_value, p_value = stats.f_oneway(group1, group2, group3)\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "mean = np.mean(data)\n",
    "sst = np.sum((data - mean) ** 2)\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "group_means = [np.mean(group1), np.mean(group2), np.mean(group3)]\n",
    "sse = np.sum((group_means - mean) ** 2) * len(group1)\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "print(\"Total sum of squares (SST):\", sst)\n",
    "print(\"Explained sum of squares (SSE):\", sse)\n",
    "print(\"Residual sum of squares (SSR):\", ssr)\n",
    "print(\"F-value:\", f_value)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d1286-7f2a-4196-b281-0f6551cb6126",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "842a50a3-6a30-4ffa-aea7-0178e57612e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effect of Factor 1: 5.000000000000014\n",
      "Main effect of Factor 2: 20.000000000000053\n",
      "Interaction effect: 1.540743955509789e-32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Define the data for each group\n",
    "group1 = [1, 2, 3, 4, 5]\n",
    "group2 = [3, 4, 5, 6, 7]\n",
    "group3 = [2, 3, 4, 5, 6]\n",
    "group4 = [4, 5, 6, 7, 8]\n",
    "\n",
    "# Combine the data into a single array\n",
    "data = np.concatenate([group1, group2, group3, group4])\n",
    "\n",
    "# Define the group labels for each factor\n",
    "factor1_labels = ['Factor 1'] * len(group1) + ['Factor 1'] * len(group2) + ['Factor 2'] * len(group3) + ['Factor 2'] * len(group4)\n",
    "factor2_labels = ['Level 1'] * len(group1) + ['Level 2'] * len(group2) + ['Level 1'] * len(group3) + ['Level 2'] * len(group4)\n",
    "\n",
    "# Create a DataFrame with the data and labels\n",
    "df = pd.DataFrame({'Data': data, 'Factor1': factor1_labels, 'Factor2': factor2_labels})\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "model = ols('Data ~ C(Factor1) + C(Factor2) + C(Factor1):C(Factor2)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract the main effects and interaction effects\n",
    "main_effect_factor1 = anova_table.loc['C(Factor1)', 'sum_sq']\n",
    "main_effect_factor2 = anova_table.loc['C(Factor2)', 'sum_sq']\n",
    "interaction_effect = anova_table.loc['C(Factor1):C(Factor2)', 'sum_sq']\n",
    "\n",
    "print(\"Main effect of Factor 1:\", main_effect_factor1)\n",
    "print(\"Main effect of Factor 2:\", main_effect_factor2)\n",
    "print(\"Interaction effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b2dbc-9a68-4227-ac74-a999d4572289",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e333a0a8-c60a-4b23-932a-4d28afaa1ba5",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic and p-value provide information about the differences between the groups. Let's interpret the results based on the given values: an F-statistic of 5.23 and a p-value of 0.02.\n",
    "\n",
    "The F-statistic measures the ratio of the between-group variability to the within-group variability. A larger F-statistic indicates a larger difference between the group means compared to the within-group variability. In this case, the F-statistic is 5.23.\n",
    "\n",
    "The p-value associated with the F-statistic indicates the probability of obtaining an F-statistic as extreme as the observed one, assuming that there are no real differences between the groups (i.e., the null hypothesis is true). A p-value of 0.02 means that there is a 2% chance of observing such a large F-statistic if the null hypothesis is true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4d063b-43b5-492e-a514-f2aac0dd6fe6",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35a96e2-d85b-4f5c-a681-f22c6de7cc31",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is an important consideration to ensure accurate and unbiased results. There are several methods to handle missing data, and the choice of method can have consequences on the validity of the analysis. Here are some common approaches and their potential consequences:\n",
    "\n",
    "Complete Case Analysis (Listwise deletion): This method involves excluding any participants with missing data from the analysis. While it is straightforward to implement, it can lead to a loss of statistical power and potential bias if the missingness is related to the variables of interest. Additionally, it may not be suitable if a large proportion of the data is missing.\n",
    "\n",
    "Pairwise Deletion: This method involves including participants with complete data for each specific analysis. It allows for the use of all available data but can lead to different sample sizes for different analyses, potentially affecting statistical power and introducing bias if the missingness is related to the variables being analyzed.\n",
    "\n",
    "Imputation Methods: Imputation involves replacing missing data with estimated values. Common imputation methods include mean imputation, last observation carried forward (LOCF), regression imputation, or multiple imputation. Imputation can help retain statistical power and reduce bias but relies on the assumption that the missing data mechanism is ignorable (i.e., missingness is unrelated to the unobserved values after considering the observed data). Incorrect imputation assumptions can introduce bias and affect standard errors.\n",
    "\n",
    "Mixed-effects models: Mixed-effects models, such as linear mixed models, handle missing data by estimating parameters using all available data while appropriately modeling the correlation structure. These models can account for both within-subject correlations and missing data patterns. However, they assume that the missing data mechanism is missing at random (MAR) or missing completely at random (MCAR). If these assumptions are violated, the results may be biased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f00f0c-9d78-447f-b812-743d4967f65f",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93462382-6aed-465b-97a8-9563374fadbd",
   "metadata": {},
   "source": [
    "After conducting an ANOVA and finding a significant overall difference among groups, post-hoc tests are used to determine which specific group differences are statistically significant. Here are some common post-hoc tests and when they would be used:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD): Tukey's HSD test is used when you have three or more groups and want to compare all possible pairwise differences. It controls the familywise error rate, meaning it maintains the overall Type I error rate at the desired level (usually 0.05). Tukey's HSD is suitable when you have no specific a priori hypotheses about the expected differences and want to explore all possible group comparisons.\n",
    "\n",
    "Bonferroni correction: The Bonferroni correction is a conservative method that adjusts the p-values for multiple comparisons. It is used when you have a pre-specified set of pairwise comparisons that are of particular interest. It divides the desired alpha level (usually 0.05) by the number of comparisons to control the familywise error rate. Bonferroni correction is suitable when you have specific hypotheses or planned comparisons in mind.\n",
    "\n",
    "Sidak correction: The Sidak correction is similar to the Bonferroni correction but provides slightly less conservative p-values. It is also used to adjust the significance level for multiple comparisons. Like Bonferroni, Sidak correction is suitable when you have specific hypotheses or planned comparisons.\n",
    "\n",
    "Scheffé's test: Scheffé's test is a conservative post-hoc test that is used when the number of groups is not predetermined or the number of pairwise comparisons is large. It is appropriate when you have a small sample size or when the assumptions of other post-hoc tests are violated. Scheffé's test controls the familywise error rate but is generally less powerful than Tukey's HSD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a2b952-cb08-48c5-86a1-4e672efa1abc",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a192c67-bd45-4fae-ba7e-b3928d4fb740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Define the weight loss data for each diet\n",
    "diet_A = [2.5, 3.1, 1.8, 2.9, 2.4, 2.2, 3.0, 2.7, 3.5, 2.6,\n",
    "          2.9, 3.1, 2.4, 2.7, 2.5, 2.8, 2.3, 3.2, 2.5, 2.7,\n",
    "          2.6, 2.8, 3.0, 2.9, 2.7, 2.6, 2.3, 2.4, 2.2, 2.1,\n",
    "          2.8, 3.1, 2.9, 2.7, 2.5, 2.6, 2.3, 2.4, 2.2, 2.8,\n",
    "          3.1, 2.9, 2.7, 2.5, 2.6, 2.3, 2.4, 2.2, 2.8, 3.1]\n",
    "\n",
    "diet_B = [3.8, 3.9, 4.2, 3.7, 4.0, 3.6, 3.8, 4.1, 3.7, 3.9,\n",
    "          3.6, 3.8, 3.7, 4.0, 3.9, 4.1, 3.7, 3.9, 3.6, 3.8,\n",
    "          3.7, 4.0, 3.9, 4.1, 3.7, 3.9, 3.6, 3.8, 3.7, 4.0,\n",
    "          3.9, 4.1, 3.7, 3.9, 3.6, 3.8, 3.7, 4.0, 3.9, 4.1,\n",
    "          3.7, 3.9, 3.6, 3.8, 3.7, 4.0, 3.9, 4.1, 3.7, 3.9]\n",
    "\n",
    "diet_C = [1.9, 2.2, 2.4, 1.8, 2.0, 2.1, 1.9, 2.2, 2.1, 1.8,\n",
    "          2.0, 2.1, 1.9, 2.2, 2.1, 1.8, 2.0, 2.1, 1.9, 2.2,\n",
    "          2.1, 1.8, 2.0, 2.1, 1.9, 2.2, 2.1, 1.8, 2.0, 2.1,\n",
    "          1.9, 2.2, 2.1, 1.8, 2.0, 2.1, 1.9, 2.2, 2.1, 1.8,\n",
    "          2.0, 2.1, 1.9, 2.2, 2.1, 1.8, 2.0, 2.1, 1.9, 2.2]\n",
    "\n",
    "# Combine the weight loss data into a single array\n",
    "weight_loss_data = np.concatenate([diet_A, diet_B, diet_C])\n",
    "\n",
    "# Create a grouping variable for each diet\n",
    "groups = ['Diet A'] * len(diet_A) + ['Diet B'] * len(diet_B) + ['Diet C'] * len(diet_C)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_value, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "print(\"F-statistic:\", f_value)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cfba08-41f9-4a24-9eef-d916027e940d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b518495-5dd3-44d0-8d89-c87184cb3ffe",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d06b8a8-5c74-4fd7-a479-6c3e8fc26587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Define the time data for each combination of software program and experience level\n",
    "program_A_novice = [10.2, 12.3, 11.5, 9.8, 10.9, 11.2, 10.5, 12.1, 11.7, 10.4, 11.9, 11.0, 10.8, 11.3, 11.6, 12.2, 10.7, 11.1, 12.0, 11.4]\n",
    "program_A_experienced = [9.8, 11.2, 10.5, 11.3, 10.9, 9.7, 10.2, 11.1, 10.6, 10.8, 10.3, 10.5, 11.0, 10.6, 10.9, 11.5, 10.7, 10.4, 11.2, 11.8]\n",
    "program_B_novice = [12.5, 11.9, 10.7, 12.2, 11.6, 12.0, 11.4, 10.9, 11.2, 12.1, 10.8, 11.5, 12.3, 11.1, 10.6, 12.0, 11.3, 10.4, 11.7, 11.0]\n",
    "program_B_experienced = [11.1, 10.6, 12.0, 11.3, 10.8, 11.2, 12.1, 10.4, 11.7, 11.0, 12.3, 11.5, 10.7, 11.6, 11.9, 12.2, 11.4, 10.9, 10.2, 9.7]\n",
    "program_C_novice = [10.8, 11.3, 11.6, 12.2, 10.7, 11.1, 12.0, 11.4, 11.9, 11.0, 10.2, 11.5, 9.7, 10.6, 10.9, 12.3, 11.2, 11.7, 10.4, 12.1]\n",
    "program_C_experienced = [11.3, 10.7, 11.2, 10.9, 11.5, 10.6, 12.1, 10.4, 11.7, 11.0, 9.7, 11.6, 10.8, 12.0, 11.4, 11.9, 11.1, 12.2, 10.2, 11.9]\n",
    "\n",
    "# Combine the time data into a single array\n",
    "time_data = np.concatenate([program_A_novice, program_A_experienced, program_B_novice,\n",
    "                            program_B_experienced, program_C_novice, program_C_experienced])\n",
    "\n",
    "# Define the grouping variables for software program and experience level\n",
    "program_labels = ['Program A'] * 20 + ['Program B'] * 20 + ['Program C'] * 20\n",
    "experience_labels = ['Novice'] * 10 + ['Experienced'] * 10 + ['Novice'] * 10 + ['Experienced'] * 10 + ['Novice'] * 10 + ['Experienced'] * 10\n",
    "\n",
    "# Create a DataFrame with the data and labels\n",
    "df = pd.DataFrame({'Time': time_data, 'Program': program_labels, 'Experience': experience_labels})\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "model = ols('Time ~ C(Program) + C(Experience) + C(Program):C(Experience)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract the main effects and interaction effect\n",
    "main_effect_program = anova_table.loc['C(Program)', 'sum_sq']\n",
    "main_effect_experience = anova_table.loc['C(Experience)', 'sum_sq']\n",
    "interaction_effect = anova_table.loc['C(Program):C(Experience)', 'sum_sq']\n",
    "\n",
    "print(\"Main effect of Program:\", main_effect_program)\n",
    "print(\"Main effect of Experience:\", main_effect_experience)\n",
    "print(\"Interaction effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaef267-2746-4e42-82a1-771c0f49994b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf93899a-be26-4d84-9128-4047c9b0062f",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07127a5-26bc-48c4-8911-954834568875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Define the time data for each combination of software program and experience level\n",
    "program_A_novice = [10.2, 12.3, 11.5, 9.8, 10.9, 11.2, 10.5, 12.1, 11.7, 10.4, 11.9, 11.0, 10.8, 11.3, 11.6, 12.2, 10.7, 11.1, 12.0, 11.4]\n",
    "program_A_experienced = [9.8, 11.2, 10.5, 11.3, 10.9, 9.7, 10.2, 11.1, 10.6, 10.8, 10.3, 10.5, 11.0, 10.6, 10.9, 11.5, 10.7, 10.4, 11.2, 11.8]\n",
    "program_B_novice = [12.5, 11.9, 10.7, 12.2, 11.6, 12.0, 11.4, 10.9, 11.2, 12.1, 10.8, 11.5, 12.3, 11.1, 10.6, 12.0, 11.3, 10.4, 11.7, 11.0]\n",
    "program_B_experienced = [11.1, 10.6, 12.0, 11.3, 10.8, 11.2, 12.1, 10.4, 11.7, 11.0, 12.3, 11.5, 10.7, 11.6, 11.9, 12.2, 11.4, 10.9, 10.2, 9.7]\n",
    "program_C_novice = [10.8, 11.3, 11.6, 12.2, 10.7, 11.1, 12.0, 11.4, 11.9, 11.0, 10.2, 11.5, 9.7, 10.6, 10.9, 12.3, 11.2, 11.7, 10.4, 12.1]\n",
    "program_C_experienced = [11.3, 10.7, 11.2, 10.9, 11.5, 10.6, 12.1, 10.4, 11.7, 11.0, 9.7, 11.6, 10.8, 12.0, 11.4, 11.9, 11.1, 12.2, 10.2, 11.9]\n",
    "\n",
    "# Combine the time data into a single array\n",
    "time_data = np.concatenate([program_A_novice, program_A_experienced, program_B_novice,\n",
    "                            program_B_experienced, program_C_novice, program_C_experienced])\n",
    "\n",
    "# Define the grouping variables for software program and experience level\n",
    "program_labels = ['Program A'] * 20 + ['Program B'] * 20 + ['Program C'] * 20\n",
    "experience_labels = ['Novice'] * 20 + ['Experienced'] * 20 + ['Novice'] * 20 + ['Experienced'] * 20 + ['Novice'] * 20 + ['Experienced'] * 20\n",
    "\n",
    "# Create a DataFrame with the data and labels\n",
    "df = pd.DataFrame({'Time': time_data, 'Program': program_labels, 'Experience': experience_labels})\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "model = ols('Time ~ C(Program) + C(Experience) + C(Program):C(Experience)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract the main effects and interaction effect\n",
    "main_effect_program = anova_table.loc['C(Program)', 'sum_sq']\n",
    "main_effect_experience = anova_table.loc['C(Experience)', 'sum_sq']\n",
    "interaction_effect = anova_table.loc['C(Program):C(Experience)', 'sum_sq']\n",
    "\n",
    "print(\"Main effect of Program:\", main_effect_program)\n",
    "print(\"Main effect of Experience:\", main_effect_experience)\n",
    "print(\"Interaction effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748f410-1f2d-40ab-81af-a5580863abda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa3a72-f189-41ae-914e-5b2ffcba8b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40666ca7-bc8b-4ceb-a23d-5bd0e071562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Define the daily sales data for each store\n",
    "store_A = [100, 95, 110, 105, 98, 115, 100, 105, 110, 95, 100, 105, 115, 120, 110, 100, 105, 95, 110, 105, 100, 98, 105, 100, 110, 115, 95, 100, 105, 110]\n",
    "store_B = [95, 105, 90, 100, 115, 100, 105, 110, 100, 105, 115, 120, 110, 100, 105, 95, 100, 105, 110, 95, 100, 105, 110, 115, 95, 100, 105, 110, 100, 98]\n",
    "store_C = [110, 105, 100, 98, 105, 100, 110, 115, 95, 100, 105, 110, 95, 105, 115, 120, 110, 100, 105, 95, 100, 105, 110, 100, 105, 115, 95, 100, 105, 110]\n",
    "\n",
    "# Combine the sales data into a single array\n",
    "sales_data = np.concatenate([store_A, store_B, store_C])\n",
    "\n",
    "# Create a grouping variable for each store\n",
    "stores = ['Store A'] * len(store_A) + ['Store B'] * len(store_B) + ['Store C'] * len(store_C)\n",
    "\n",
    "# Create a DataFrame with the data and labels\n",
    "df = pd.DataFrame({'Sales': sales_data, 'Store': stores})\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "rm_anova = AnovaRM(df, 'Sales', 'Store', within=['Store'])\n",
    "results = rm_anova.fit()\n",
    "\n",
    "print(results)\n",
    "\n",
    "# Conduct post-hoc tests (Tukey's HSD)\n",
    "posthoc = pairwise_tukeyhsd(df['Sales'], df['Store'])\n",
    "print(posthoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae66dbe-09d2-4a2a-9076-0c2f1545a349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
